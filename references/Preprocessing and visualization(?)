#kiwi로 띄어쓰기 전처리 필요.

from kiwipiepy import Kiwi
kiwi = Kiwi()

#형태소 단위 Tokenize
kiwi.tokenize("안녕하세요 형태소 분석기 키위입니다.")

#이어진 문장 형식을 쪼갬
kiwi.split_into_sents("여러 문장으로 구성된 텍스트네 이걸 분리해줘")

#띄어쓰기 교정...!
kiwi.space("띄어쓰기없이작성된텍스트네이걸교정해줘")

#Tokenize된 문장을 다시 합치기(Idea..?)
tokens = kiwi.tokenize("쿠팡은너무일을못하는데?")
kiwi.join(tokens)

#soynlp.normalizer로 반복되는 문자 줄이기

from soynlp.normalizer import *

#repeat_normalize는 반복되는 단어 자모를 없앰.
print(repeat_normalize('쿠팡ㅋㅋㅋㅋㅋㅋㅋㅋㅋ너무무무무무무 못하는걸?', num_repeats=2))

#normalize는 한글만 남기고 다 없앰
print(normalize('Lotte쿠팡 배송 너무%%%%못하는데 ㅋㅋㅋㅋㅋ??~!!'))

# 띄어쓰기 전처리된 데이터를 soynlp를 이용해 Tokenization 및 단어 빈도 분석

import sys
sys.path.insert(0, 'C:/Users/SeaTurtle/Desktop/workspace/learn/ramyeon_reviews.json')
from soynlp.noun import LRNounExtractor

noun_extractor = LRNounExtractor(
    max_left_length=10, 
    max_right_length=7,
    predictor_fnames=None,
    verbose=True
)

from soynlp.utils import DoublespaceLineCorpus

corpus_fname = 'C:/Users/SeaTurtle/Desktop/workspace/learn/ramyeon_reviews.json'
sentences = DoublespaceLineCorpus(corpus_fname, iter_sent=True)
len(sentences)

nouns = noun_extractor.train_extract(
    sentences,
    min_noun_score=0.3,
    min_noun_frequency=20
)


# L-R NounExtractor로 빈도수 및 명사점수 뽑아내기 (n 어떻게 없애는지,,,)

import sys
sys.path.insert(0, 'C:/Users/SeaTurtle/Desktop/workspace/learn/ramyeon_reviews.json')
from soynlp.noun import LRNounExtractor

noun_extractor = LRNounExtractor(
    max_left_length=10, 
    max_right_length=7,
    predictor_fnames=None,
    verbose=True
)

from soynlp.utils import DoublespaceLineCorpus

corpus_fname = 'C:/Users/SeaTurtle/Desktop/workspace/learn/ramyeon_reviews.json'
sentences = DoublespaceLineCorpus(corpus_fname, iter_sent=True)
len(sentences)

nouns = noun_extractor.train_extract(
    sentences,
    min_noun_score=0.3,
    min_noun_frequency=20
)

#빈도수x명사점수 기준으로 상위 100개 단어
top100 = sorted(nouns.items(), 
    key=lambda x:-x[1].frequency * x[1].score)[:100]

for i, (word, score) in enumerate(top100):
    if i % 5 == 0:
        print()
    print('%6s (%.2f)' % (word, score.score), end='')
    
# 분석된 단어 빈도를 matplotlib으로 시각화하기
